

# ğŸµ Real-Time Audio Visualisation â€” Workflow Overview

## **1. Project Concept**
This project creates a **real-time audio visualiser** that converts live sound input into animated graphical patterns.  
- **Python** handles audio capture and analysis.  
- **JavaScript (WebGL)** handles visual rendering.  
- The two communicate via a **local low-latency connection** (WebSocket, UDP, or pipe).

---

## **2. Workflow Diagram**

```text
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚        Microphone         â”‚
 â”‚ (System audio interface)  â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚  Raw audio samples
              â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚   Python Audio Engine     â”‚
 â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
 â”‚ â€¢ Capture stream (sounddevice / pyaudio)
 â”‚ â€¢ Buffer small chunks (256â€“512 samples)
 â”‚ â€¢ Apply FFT + smoothing (NumPy)
 â”‚ â€¢ Compute metrics:
 â”‚     - Amplitude (RMS)
 â”‚     - Frequency bands
 â”‚     - Peak energy
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚  JSON / binary packet
              â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  Local Transport Layer    â”‚
 â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
 â”‚ â€¢ WebSocket / UDP / Pipe  â”‚
 â”‚ â€¢ Persistent low-latency  â”‚
 â”‚   connection on localhost â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚  Data stream (~60 fps)
              â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  JS Visualisation Engine  â”‚
 â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
 â”‚ â€¢ Receive audio metrics   â”‚
 â”‚ â€¢ Map values to visuals:  â”‚
 â”‚     - Volume â†’ brightness
 â”‚     - Frequency â†’ colour
 â”‚     - Beat â†’ motion pulse
 â”‚ â€¢ GPU render (WebGL / Three.js)
 â”‚ â€¢ Maintain 30â€“60 fps loop â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚     Display Window        â”‚
 â”‚  (Electron / CEF app)     â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## **3. Stage Summary**

| Stage | Description | Technology |
|--------|--------------|-------------|
| **Audio Capture** | Record live sound from the system microphone. | Python (`sounddevice` / `pyaudio`) |
| **Processing** | Analyse the waveform using FFT to extract amplitude and frequency data. | Python (`NumPy`) |
| **Streaming** | Send processed data packets to the renderer with minimal delay. | WebSocket / UDP |
| **Rendering** | Draw visuals that react dynamically to audio data. | JavaScript (`WebGL`, `Three.js`) |
| **Display** | Show the animation in a standalone desktop window. | Electron / CEF |

---

## **4. Performance Targets**

| Stage | Target Time | Notes |
|--------|--------------|-------|
| Audio capture | 10â€“20 ms | System buffer dependent |
| FFT & processing | 1â€“5 ms | NumPy acceleration |
| Serialisation & transport | < 10 ms | Localhost latency |
| Rendering | 1â€“5 ms | GPU-accelerated WebGL |
| **Total latency** | **< 50 ms** | Real-time perception threshold |

---

## **5. Design Principles**
- **Separation of Concerns:** Keep audio logic, transport, and graphics modular.  
- **Low-Latency Streaming:** Maintain a persistent connection to avoid polling delay.  
- **GPU Utilisation:** Offload rendering to GPU for smooth performance.  
- **Cross-Platform Compatibility:** Works on Windows, macOS, and Linux.  

---

## **6. Project Milestones**

### **Milestone 1 (MVP)**
- Capture live mic input.  
- Compute amplitude (RMS).  
- Send amplitude to renderer to change colour brightness.  

### **Milestone 2**
- Add FFT frequency analysis.  
- Create bar-style visualiser.  
- Introduce simple particle effects.  

### **Milestone 3**
- Add smoothing and peak detection.  
- Experiment with multiple visual modes.  
- Record or export visualisation sessions.

---

## **7. Next Steps**
- Finalise data exchange format (JSON structure).  
- Prototype audio capture in Python.  
- Build basic WebSocket server.  
- Develop simple JS client to visualise amplitude.  

---

Created by **Oliver Barkham**  
For **A Level Computer Science NEA** â€” Real-Time Audio Visualisation Project